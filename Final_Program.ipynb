{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjDzF4UIJSEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "8da31955-4eb2-46c6-efe1-d7c6c5ff4a77"
      },
      "source": [
        "#Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bguLxUQWJZVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcd6288d-04ca-4f09-9161-7c39f67b58cb"
      },
      "source": [
        "#Change the directory to the path where you have all your input files\n",
        "%cd /content/drive/My Drive/Blackcoffer - Data Science Internship\n",
        "#Below command shows you all thee files present in your current directory\n",
        "#!ls"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Blackcoffer - Data Science Internship\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muq2FaT6XSUy",
        "colab_type": "text"
      },
      "source": [
        "### **Main Program Begins**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWWYR_PqJb7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5d4d84aa-1568-402e-a13e-6d07146bd386"
      },
      "source": [
        "################################################################################\n",
        "#              IMPORT ALL THE REQUIRED PACKAGES                                 |\n",
        "################################################################################\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "import urllib.request\n",
        "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib_7z4NWJs33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4d880d44-e14d-4975-f01e-7d0909b01071"
      },
      "source": [
        "################################################################################\n",
        "#              FETCH THE DATA FROM cik_lis.xlsx file                            |\n",
        "################################################################################\n",
        "\n",
        "org_file         = pd.read_excel(\"cik_list.xlsx\", header=None) #Reading the data from the Excel file into a DataFrame\n",
        "header           = org_file.iloc[0,:]                          #The header column names are being fetched \n",
        "org_file.columns = header                                      #The header column names are being assigned as the dataframe column names\n",
        "secfname_or      = org_file.copy()                             #Passing the dataframe values to secfname_or dataframe\n",
        "secfname_or      = secfname_or.iloc[1:,5]                      #Fetching the SECFNAME column from the dataframe\n",
        "file_rec         = org_file.iloc[1:,:]                         #1 is given instead of 0 because we do not want header as one of the record\n",
        "file_rec.head(5)                                               #file_rec contains all the data from the cik_lis.xlsx file"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CIK</th>\n",
              "      <th>CONAME</th>\n",
              "      <th>FYRMO</th>\n",
              "      <th>FDATE</th>\n",
              "      <th>FORM</th>\n",
              "      <th>SECFNAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199803</td>\n",
              "      <td>1998-03-06 00:00:00</td>\n",
              "      <td>10-K405</td>\n",
              "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199805</td>\n",
              "      <td>1998-05-15 00:00:00</td>\n",
              "      <td>10-Q</td>\n",
              "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199808</td>\n",
              "      <td>1998-08-13 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199811</td>\n",
              "      <td>1998-11-12 00:00:00</td>\n",
              "      <td>10-K/A</td>\n",
              "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199811</td>\n",
              "      <td>1998-11-16 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0         CIK  ...                                  SECFNAME\n",
              "1  0000003662  ...  edgar/data/3662/0000950170-98-000413.txt\n",
              "2  0000003662  ...  edgar/data/3662/0000950170-98-001001.txt\n",
              "3  0000003662  ...  edgar/data/3662/0000950172-98-000783.txt\n",
              "4  0000003662  ...  edgar/data/3662/0000950170-98-002145.txt\n",
              "5  0000003662  ...  edgar/data/3662/0000950172-98-001203.txt\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjQVo-zgKIq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "2e481a6f-0c8b-4849-b5e9-d44ca5e305bb"
      },
      "source": [
        "################################################################################\n",
        "#          Add the link at the pre-fix to make values as a hyperlink            |\n",
        "################################################################################\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "#Add the below link at the prefix of all the values in SECFNAME column\n",
        "link = 'https://www.sec.gov/Archives/'\n",
        "file_rec['SECFNAME'] = link + file_rec['SECFNAME'].astype(str)\n",
        "\n",
        "#Now all the values in the SECFNAME column have become hyperlinks linking to \n",
        "#HTML pages\n",
        "file_rec.head(5)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CIK</th>\n",
              "      <th>CONAME</th>\n",
              "      <th>FYRMO</th>\n",
              "      <th>FDATE</th>\n",
              "      <th>FORM</th>\n",
              "      <th>SECFNAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199803</td>\n",
              "      <td>1998-03-06 00:00:00</td>\n",
              "      <td>10-K405</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199805</td>\n",
              "      <td>1998-05-15 00:00:00</td>\n",
              "      <td>10-Q</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199808</td>\n",
              "      <td>1998-08-13 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199811</td>\n",
              "      <td>1998-11-12 00:00:00</td>\n",
              "      <td>10-K/A</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199811</td>\n",
              "      <td>1998-11-16 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0         CIK  ...                                           SECFNAME\n",
              "1  0000003662  ...  https://www.sec.gov/Archives/edgar/data/3662/0...\n",
              "2  0000003662  ...  https://www.sec.gov/Archives/edgar/data/3662/0...\n",
              "3  0000003662  ...  https://www.sec.gov/Archives/edgar/data/3662/0...\n",
              "4  0000003662  ...  https://www.sec.gov/Archives/edgar/data/3662/0...\n",
              "5  0000003662  ...  https://www.sec.gov/Archives/edgar/data/3662/0...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PWm0SfJK28x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "c71c96d9-beb6-442f-b501-5bcacc5d5733"
      },
      "source": [
        "###############################################################################################################################################################################\n",
        "#                                                      Add the additional columns to file_rec dataframe                                                                        |\n",
        "###############################################################################################################################################################################\n",
        "\n",
        "new_columns = ['mda_positive_score', 'mda_negative_score', 'mda_polarity_score', 'mda_average_sentence_length', 'mda_percentage_of_complex_words', 'mda_fog_index',\n",
        "               'mda_complex_word_count', 'mda_word_count', 'mda_uncertainty_score', 'mda_constraining_score', 'mda_positive_word_proportion', 'mda_negative_word_proportion',\n",
        "               'mda_uncertainty_word_proportion', 'mda_constraining_word_proportion','qqdmr_positive_score','qqdmr_negative_score',\n",
        "               'qqdmr_polarity_score','qqdmr_average_sentence_length','qqdmr_percentage_of_complex_words', 'qqdmr_fog_index','qqdmr_complex_word_count',\n",
        "               'qqdmr_word_count', 'qqdmr_uncertainty_score', 'qqdmr_constraining_score', 'qqdmr_positive_word_proportion', 'qqdmr_negative_word_proportion',\n",
        "               'qqdmr_uncertainty_word_proportion', 'qqdmr_constraining_word_proportion', 'rf_positive_score', 'rf_negative_score',\n",
        "               'rf_polarity_score', 'rf_average_sentence_length', 'rf_percentage_of_complex_words', 'rf_fog_index', 'rf_complex_word_count',\n",
        "               'rf_word_count', 'rf_uncertainty_score', 'rf_constraining_score', 'rf_positive_word_proportion', 'rf_negative_word_proportion',\n",
        "               'rf_uncertainty_word_proportion', 'rf_constraining_word_proportion', 'constraining_words_whole_report']\n",
        "\n",
        "file_rec = pd.concat([file_rec,pd.DataFrame(columns=new_columns)]) #Appends the above columns to the existing dataframe file_rec\n",
        "file_rec = file_rec.reset_index()                                  #Resets the row index of the dataframe starting from 0\n",
        "del file_rec['index']                                              #Deleting the redundant index column from the dataframe\n",
        "file_rec.head(3)                                                   #Show the first 3 records of the dataframe"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CIK</th>\n",
              "      <th>CONAME</th>\n",
              "      <th>FYRMO</th>\n",
              "      <th>FDATE</th>\n",
              "      <th>FORM</th>\n",
              "      <th>SECFNAME</th>\n",
              "      <th>mda_positive_score</th>\n",
              "      <th>mda_negative_score</th>\n",
              "      <th>mda_polarity_score</th>\n",
              "      <th>mda_average_sentence_length</th>\n",
              "      <th>mda_percentage_of_complex_words</th>\n",
              "      <th>mda_fog_index</th>\n",
              "      <th>mda_complex_word_count</th>\n",
              "      <th>mda_word_count</th>\n",
              "      <th>mda_uncertainty_score</th>\n",
              "      <th>mda_constraining_score</th>\n",
              "      <th>mda_positive_word_proportion</th>\n",
              "      <th>mda_negative_word_proportion</th>\n",
              "      <th>mda_uncertainty_word_proportion</th>\n",
              "      <th>mda_constraining_word_proportion</th>\n",
              "      <th>qqdmr_positive_score</th>\n",
              "      <th>qqdmr_negative_score</th>\n",
              "      <th>qqdmr_polarity_score</th>\n",
              "      <th>qqdmr_average_sentence_length</th>\n",
              "      <th>qqdmr_percentage_of_complex_words</th>\n",
              "      <th>qqdmr_fog_index</th>\n",
              "      <th>qqdmr_complex_word_count</th>\n",
              "      <th>qqdmr_word_count</th>\n",
              "      <th>qqdmr_uncertainty_score</th>\n",
              "      <th>qqdmr_constraining_score</th>\n",
              "      <th>qqdmr_positive_word_proportion</th>\n",
              "      <th>qqdmr_negative_word_proportion</th>\n",
              "      <th>qqdmr_uncertainty_word_proportion</th>\n",
              "      <th>qqdmr_constraining_word_proportion</th>\n",
              "      <th>rf_positive_score</th>\n",
              "      <th>rf_negative_score</th>\n",
              "      <th>rf_polarity_score</th>\n",
              "      <th>rf_average_sentence_length</th>\n",
              "      <th>rf_percentage_of_complex_words</th>\n",
              "      <th>rf_fog_index</th>\n",
              "      <th>rf_complex_word_count</th>\n",
              "      <th>rf_word_count</th>\n",
              "      <th>rf_uncertainty_score</th>\n",
              "      <th>rf_constraining_score</th>\n",
              "      <th>rf_positive_word_proportion</th>\n",
              "      <th>rf_negative_word_proportion</th>\n",
              "      <th>rf_uncertainty_word_proportion</th>\n",
              "      <th>rf_constraining_word_proportion</th>\n",
              "      <th>constraining_words_whole_report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199803</td>\n",
              "      <td>1998-03-06 00:00:00</td>\n",
              "      <td>10-K405</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199805</td>\n",
              "      <td>1998-05-15 00:00:00</td>\n",
              "      <td>10-Q</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199808</td>\n",
              "      <td>1998-08-13 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          CIK  ... constraining_words_whole_report\n",
              "0  0000003662  ...                             NaN\n",
              "1  0000003662  ...                             NaN\n",
              "2  0000003662  ...                             NaN\n",
              "\n",
              "[3 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otKzDhS7MprN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "f215e953-9c70-4584-d796-f7a6b3ae648f"
      },
      "source": [
        "################################################################################\n",
        "#          Final DataFrame for calculations - file_rec                          |\n",
        "################################################################################\n",
        "\n",
        "file_rec.head(3)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CIK</th>\n",
              "      <th>CONAME</th>\n",
              "      <th>FYRMO</th>\n",
              "      <th>FDATE</th>\n",
              "      <th>FORM</th>\n",
              "      <th>SECFNAME</th>\n",
              "      <th>mda_positive_score</th>\n",
              "      <th>mda_negative_score</th>\n",
              "      <th>mda_polarity_score</th>\n",
              "      <th>mda_average_sentence_length</th>\n",
              "      <th>mda_percentage_of_complex_words</th>\n",
              "      <th>mda_fog_index</th>\n",
              "      <th>mda_complex_word_count</th>\n",
              "      <th>mda_word_count</th>\n",
              "      <th>mda_uncertainty_score</th>\n",
              "      <th>mda_constraining_score</th>\n",
              "      <th>mda_positive_word_proportion</th>\n",
              "      <th>mda_negative_word_proportion</th>\n",
              "      <th>mda_uncertainty_word_proportion</th>\n",
              "      <th>mda_constraining_word_proportion</th>\n",
              "      <th>qqdmr_positive_score</th>\n",
              "      <th>qqdmr_negative_score</th>\n",
              "      <th>qqdmr_polarity_score</th>\n",
              "      <th>qqdmr_average_sentence_length</th>\n",
              "      <th>qqdmr_percentage_of_complex_words</th>\n",
              "      <th>qqdmr_fog_index</th>\n",
              "      <th>qqdmr_complex_word_count</th>\n",
              "      <th>qqdmr_word_count</th>\n",
              "      <th>qqdmr_uncertainty_score</th>\n",
              "      <th>qqdmr_constraining_score</th>\n",
              "      <th>qqdmr_positive_word_proportion</th>\n",
              "      <th>qqdmr_negative_word_proportion</th>\n",
              "      <th>qqdmr_uncertainty_word_proportion</th>\n",
              "      <th>qqdmr_constraining_word_proportion</th>\n",
              "      <th>rf_positive_score</th>\n",
              "      <th>rf_negative_score</th>\n",
              "      <th>rf_polarity_score</th>\n",
              "      <th>rf_average_sentence_length</th>\n",
              "      <th>rf_percentage_of_complex_words</th>\n",
              "      <th>rf_fog_index</th>\n",
              "      <th>rf_complex_word_count</th>\n",
              "      <th>rf_word_count</th>\n",
              "      <th>rf_uncertainty_score</th>\n",
              "      <th>rf_constraining_score</th>\n",
              "      <th>rf_positive_word_proportion</th>\n",
              "      <th>rf_negative_word_proportion</th>\n",
              "      <th>rf_uncertainty_word_proportion</th>\n",
              "      <th>rf_constraining_word_proportion</th>\n",
              "      <th>constraining_words_whole_report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199803</td>\n",
              "      <td>1998-03-06 00:00:00</td>\n",
              "      <td>10-K405</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199805</td>\n",
              "      <td>1998-05-15 00:00:00</td>\n",
              "      <td>10-Q</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199808</td>\n",
              "      <td>1998-08-13 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          CIK  ... constraining_words_whole_report\n",
              "0  0000003662  ...                             NaN\n",
              "1  0000003662  ...                             NaN\n",
              "2  0000003662  ...                             NaN\n",
              "\n",
              "[3 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ1jg7QEM8GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################################################################################################################\n",
        "#                                                                   COMPLETE PROCESS FLOW                                                                                      |\n",
        "###############################################################################################################################################################################\n",
        "\n",
        "#STEP 1 : Loop through the file_rec. In every iteration we fetch url data from the SECFNAME column in the file_rec dataframe.\n",
        "#STEP 2 : In every iteration, We read the data from the HTML webpage using the URL Link \n",
        "#STEP 3 : After reading the data from the HTML page, we remove the HTML components from it and get clean text data\n",
        "#         We concatenate all of that text data into a single string. \n",
        "#         This has been done to avoid another loop inside it, thus increasing speed of operation\n",
        "#STEP 4 : Once the data is ready using the above operations, we then go for fetching specific sections data using the function fetch_sections_data()\n",
        "#STEP 5 : HOW IS THE SECTIONS DATA FETCHED ?\n",
        "#         The sections data is fetched using a very simple approach. For example: if we want to extract \"RISK FACTORS\" section data, this sections data\n",
        "#         would be present in the Table of Contents and in the main section where the Actual topic would be present.\n",
        "#         Since we would be needing only the Actual Topic data instead of the heading name in Table of contents, I am searching for the number of occurences\n",
        "#         of \"RISK FACTORS\"(UPPERCASE) in my data. I am looking only for UPPERCASE because the part where Actual data is present starts with \"RISK FACTORS\" name\n",
        "#         in the upper case only. So once I find the occurence of RISK FACTORS in my data, I slice my data to start it from that position. But where to end it now?\n",
        "#         To knoww the part where I have to end it is decided by the \"ITEM\"(UPPERCASE) name. Each section corresponds to one ITEM number. So RISK FACTORS corresponds to ITEM 2,\n",
        "#         its next topic should be ITEM 3. So I am looking for the position of ITEM in my sliced data. The part where ITEM begins would be my end point.\n",
        "\n",
        "#         But what if Table of contents also contains \"RISK FACTORS\" name in Upper case?\n",
        "#         Well for this case, I am removing the Table of Contents from my data.\n",
        "#         So, this would ensure that whatever data I am fetching is completely related to the section I am looking for.\n",
        "#STEP 6 : Once all the 3 sections data has been fetched, we perform all the required calculations on it."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKMPiDk7U2mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                                  FETCHING THE OTHER REQUIRED FILES DATA                                          |\n",
        "###################################################################################################################\n",
        "\n",
        "#Fetching the Stop words list\n",
        "with open('StopWords_GenericLong.txt') as f:\n",
        "   stop_words = list(f) \n",
        "   stop_words = [s.rstrip() for s in stop_words]\n",
        "   stop_words = [x.lower() for x in stop_words]\n",
        "\n",
        "#Fetching the list of Positive and Negative words\n",
        "positive = pd.read_excel(\"LoughranMcDonald_SentimentWordLists_2018.xlsx\", \"Positive\", header=None)\n",
        "negative = pd.read_excel(\"LoughranMcDonald_SentimentWordLists_2018.xlsx\", \"Negative\", header=None)\n",
        "\n",
        "#Fetching all the positive and Negative words into two separate lists\n",
        "positive = positive[0]\n",
        "negative = negative[0]\n",
        "\n",
        "#Keeping all the positive and Negative words which are not present in stop words list\n",
        "positive_cleaned = list(set(positive)-set(stop_words)) \n",
        "negative_cleaned = list(set(negative)-set(stop_words)) \n",
        "\n",
        "#Converting the Positive and Negative words to Lowercase\n",
        "positive_cleaned = [x.lower() for x in positive_cleaned]\n",
        "negative_cleaned = [x.lower() for x in negative_cleaned]\n",
        "\n",
        "#Fetching the uncertainity and constarining words from the Excel sheet\n",
        "uncertainity_dict = pd.read_excel(\"uncertainty_dictionary.xlsx\", header=None)\n",
        "constraining_dict     = pd.read_excel(\"constraining_dictionary.xlsx\", header=None)\n",
        "\n",
        "#Passing all the above obtained words into separate lists and converting it to Lowercase\n",
        "uncertainity_words = uncertainity_dict[0].tolist()\n",
        "uncertainity_words = [x.lower() for x in uncertainity_words]\n",
        "\n",
        "constraining_words = constraining_dict[0].tolist()\n",
        "constraining_words = [x.lower() for x in constraining_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-XCFmpaSBgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe729c61-01f8-4aa9-ca34-68b07964d1f4"
      },
      "source": [
        "###################################################################################################################\n",
        "#                                      MAIN PROGRAM OPERATIONS                                                     |\n",
        "###################################################################################################################\n",
        "\n",
        "for i in range(len(file_rec)):                    #Looping through the file_rec dataframe\n",
        "  \n",
        "  url = file_rec.iloc[i,5]                        #Fetching the URL from the dataframe\n",
        "  data = urllib.request.urlopen(url).readlines()  #Reading the contents from the URL link page\n",
        "  \n",
        "  #Data cleaning to optimize the speed and efficiency of operation\n",
        "  data = [str(s, 'utf-8') for s in data]          #Decoding the variable to remove b(bytes object) at the beginning\n",
        "  data = [s.strip('\\n') for s in data]            #Removing the new line character \\n at the end of every line\n",
        "  data = list(filter(None, data))                 #Removing the lines which are blank\n",
        "  #After doing the above operations the number of iterations required now would be less\n",
        "\n",
        "  #Converting the list of strings into a single string to increase speed of operation instead of looping again\n",
        "  data = \" \".join(data)\n",
        "\n",
        "  #Removing the Tables from the data\n",
        "  data = re.sub(\"(?is)<table[^>]*>(.*?)<\\/table>\", \"\", data)\n",
        "\n",
        "  #REGEX operations to remove the HTML content from our data and get a clean text data\n",
        "  html_regex = re.compile(r'<.*?>')\n",
        "  data = re.sub(html_regex,'',data)\n",
        "  data = data.replace('&nbsp;','')\n",
        "  input_data = re.sub(r'&#\\d+;', '', data)   \n",
        "\n",
        "  #Calculating the Constraining words for the whole report\n",
        "  constr_whole_count = constr_whole_report(input_data)\n",
        "  file_rec.loc[i, 'constraining_words_whole_report'] = constr_whole_count\n",
        "\n",
        "  #Fetching the sections data using the fetch_sections_data()\n",
        "  topic1_data, topic2_data, topic3_data = fetch_sections_data(input_data)\n",
        "\n",
        "  #Removing the Stop words, punctuations in our data\n",
        "  topic1_data, topic2_data, topic3_data = data_cleaning(topic1_data, topic2_data, topic3_data)\n",
        "\n",
        "################################################################################\n",
        "#   Calculating the values for \"MANAGEMENT'S DISCUSSION AND ANALYSIS\" section   |\n",
        "################################################################################\n",
        "\n",
        "  if (topic1_data != 0):\n",
        "    \n",
        "    #Calculating the positive score, negative score and Polarity score\n",
        "    pos_score1, neg_score1, pol_score1 = pos_neg_pol(topic1_data)\n",
        "\n",
        "    #Passing the above values to our corresponding dataframe records\n",
        "    file_rec.loc[i, 'mda_positive_score'] = pos_score1\n",
        "    file_rec.loc[i, 'mda_negative_score'] = neg_score1 \n",
        "    file_rec.loc[i, 'mda_polarity_score'] = pol_score1\n",
        "\n",
        "    #Calculating the average sentence length for our section of data\n",
        "    avg_sent_len_val1 = avg_sent_len(topic1_data)\n",
        "    file_rec.loc[i, 'mda_average_sentence_length'] = avg_sent_len_val1\n",
        "\n",
        "    #Calculating the word count, complex word count and percentage of complex words\n",
        "    complex_count = 0\n",
        "    word_count1, complex_count1, perc_complex_words1 = complex_word_count(topic1_data, complex_count)\n",
        "    file_rec.loc[i, 'mda_word_count']                  = word_count1\n",
        "    file_rec.loc[i, 'mda_complex_word_count']          = complex_count1\n",
        "    file_rec.loc[i, 'mda_percentage_of_complex_words'] = perc_complex_words1\n",
        "\n",
        "    #Calculating the Fog index value \n",
        "    fog_index1 = 0.4 * (avg_sent_len_val1 + perc_complex_words1)\n",
        "    file_rec.loc[i, 'mda_fog_index'] = fog_index1\n",
        "\n",
        "    #Calculating the uncertainity score and constraining score\n",
        "    uncer_score1, constr_score1 = uncer_constr_calc(topic1_data)\n",
        "    perc_uncer1  = uncer_score1/word_count1\n",
        "    perc_constr1 = constr_score1/word_count1\n",
        "    file_rec.loc[i, 'mda_uncertainty_score']            = uncer_score1\n",
        "    file_rec.loc[i, 'mda_constraining_score']           = constr_score1\n",
        "\n",
        "    #Calculating the Uncertainity and Constraining word proportion\n",
        "    file_rec.loc[i, 'mda_uncertainty_word_proportion']  = perc_uncer1\n",
        "    file_rec.loc[i, 'mda_constraining_word_proportion'] = perc_constr1\n",
        "    \n",
        "    #Calculating the Positive and Negative word proportion\n",
        "    perc_positive1 = pos_score1/word_count1\n",
        "    perc_negative1 = neg_score1/word_count1\n",
        "    file_rec.loc[i, 'mda_positive_word_proportion']  = perc_positive1\n",
        "    file_rec.loc[i, 'mda_negative_word_proportion']  = perc_negative1\n",
        "\n",
        "  else:\n",
        "    #If the section 1 data is not available, all the below values should be 0\n",
        "    file_rec.loc[i, 6:21] = 0\n",
        "\n",
        "#####################################################################################################\n",
        "#  Calculating the values for \"QUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK\" section   |\n",
        "#####################################################################################################\n",
        "\n",
        "  if (topic2_data != 0):  \n",
        "    \n",
        "    #Calculating the positive score, negative score and Polarity score\n",
        "    pos_score2, neg_score2, pol_score2 = pos_neg_pol(topic2_data)\n",
        "    #Passing the above values to our corresponding dataframe records\n",
        "    file_rec.loc[i, 'qqdmr_positive_score'] = pos_score2\n",
        "    file_rec.loc[i, 'qqdmr_negative_score'] = neg_score2 \n",
        "    file_rec.loc[i, 'qqdmr_polarity_score'] = pol_score2\n",
        "\n",
        "    #Calculating the average sentence length for our section of data\n",
        "    avg_sent_len_val2 = avg_sent_len(topic2_data)\n",
        "    file_rec.loc[i, 'qqdmr_average_sentence_length'] = avg_sent_len_val2\n",
        "\n",
        "    #Calculating the word count, complex word count and percentage of complex words\n",
        "    complex_count = 0\n",
        "    word_count2, complex_count2, perc_complex_words2 = complex_word_count(topic2_data, complex_count)\n",
        "    file_rec.loc[i, 'qqdmr_word_count']                  = word_count2\n",
        "    file_rec.loc[i, 'qqdmr_complex_word_count']          = complex_count2\n",
        "    file_rec.loc[i, 'qqdmr_percentage_of_complex_words'] = perc_complex_words2\n",
        "\n",
        "    #Calculating the Fog index value \n",
        "    fog_index2 = 0.4 * (avg_sent_len_val2 + perc_complex_words2)\n",
        "    file_rec.loc[i, 'qqdmr_fog_index'] = fog_index2\n",
        "\n",
        "    #Calculating the uncertainity score and constraining score\n",
        "    uncer_score2, constr_score2 = uncer_constr_calc(topic2_data)\n",
        "    perc_uncer2  = uncer_score2/word_count2\n",
        "    perc_constr2 = constr_score2/word_count2\n",
        "    file_rec.loc[i, 'qqdmr_uncertainty_score']            = uncer_score2\n",
        "    file_rec.loc[i, 'qqdmr_constraining_score']           = constr_score2\n",
        "\n",
        "    #Calculating the Uncertainity and Constraining word proportion\n",
        "    file_rec.loc[i, 'qqdmr_uncertainty_word_proportion']  = perc_uncer2\n",
        "    file_rec.loc[i, 'qqdmr_constraining_word_proportion'] = perc_constr2\n",
        "    \n",
        "    #Calculating the Positive and Negative word proportion\n",
        "    perc_positive2 = pos_score2/word_count2\n",
        "    perc_negative2 = neg_score2/word_count2\n",
        "    file_rec.loc[i, 'qqdmr_positive_word_proportion']  = perc_positive2\n",
        "    file_rec.loc[i, 'qqdmr_negative_word_proportion']  = perc_negative2\n",
        "\n",
        "  else:\n",
        "    #If the section 2 data is not available, all the below values should be 0\n",
        "    file_rec.loc[i, 20:33] = 0\n",
        "\n",
        "################################################################################\n",
        "#            Calculating the values for \"RISK FACTORS\" section                  |\n",
        "################################################################################\n",
        "\n",
        "  if (topic3_data != 0):  \n",
        "    \n",
        "    #Calculating the positive score, negative score and Polarity score\n",
        "    pos_score3, neg_score3, pol_score3 = pos_neg_pol(topic3_data)\n",
        "    #Passing the above values to our corresponding dataframe records\n",
        "    file_rec.loc[i, 'rf_positive_score'] = pos_score3\n",
        "    file_rec.loc[i, 'rf_negative_score'] = neg_score3 \n",
        "    file_rec.loc[i, 'rf_polarity_score'] = pol_score3\n",
        "\n",
        "    #Calculating the average sentence length for our section of data\n",
        "    avg_sent_len_val3 = avg_sent_len(topic3_data)\n",
        "    file_rec.loc[i, 'rf_average_sentence_length'] = avg_sent_len_val3\n",
        "\n",
        "    #Calculating the word count, complex word count and percentage of complex words\n",
        "    complex_count = 0\n",
        "    word_count3, complex_count3, perc_complex_words3 = complex_word_count(topic3_data, complex_count)\n",
        "    file_rec.loc[i, 'rf_word_count']                  = word_count3\n",
        "    file_rec.loc[i, 'rf_complex_word_count']          = complex_count3\n",
        "    file_rec.loc[i, 'rf_percentage_of_complex_words'] = perc_complex_words3\n",
        "\n",
        "    #Calculating the Fog index value \n",
        "    fog_index3 = 0.4 * (avg_sent_len_val3 + perc_complex_words3)\n",
        "    file_rec.loc[i, 'rf_fog_index'] = fog_index3\n",
        "\n",
        "    #Calculating the uncertainity score and constraining score\n",
        "    uncer_score3, constr_score3 = uncer_constr_calc(topic3_data)\n",
        "    perc_uncer3  = uncer_score3/word_count3\n",
        "    perc_constr3 = constr_score3/word_count3\n",
        "    file_rec.loc[i, 'rf_uncertainty_score']            = uncer_score3\n",
        "    file_rec.loc[i, 'rf_constraining_score']           = constr_score3\n",
        "    #Calculating the Uncertainity and Constraining word proportion\n",
        "    file_rec.loc[i, 'rf_uncertainty_word_proportion']  = perc_uncer3\n",
        "    file_rec.loc[i, 'rf_constraining_word_proportion'] = perc_constr3\n",
        "    \n",
        "    #Calculating the Positive and Negative word proportion\n",
        "    perc_positive3 = pos_score3/word_count3\n",
        "    perc_negative3 = neg_score3/word_count3\n",
        "    file_rec.loc[i, 'rf_positive_word_proportion']  = perc_positive3\n",
        "    file_rec.loc[i, 'rf_negative_word_proportion']  = perc_negative3\n",
        "\n",
        "  else:\n",
        "    #If the section 1 data is not available, all the below values should be 0\n",
        "    file_rec.loc[i, 34:47] = 0\n",
        "\n",
        "  #Clearing all the variables\n",
        "  pos_score1 = neg_score1 = pol_score1 = avg_sent_len_val1 = word_count1 = complex_count1 = perc_complex_words1 = fog_index1 = uncer_score1 = constr_score1 = perc_uncer1 = perc_constr1 = perc_positive1 = perc_negative1 = 0\n",
        "  pos_score2 = neg_score2 = pol_score2 = avg_sent_len_val2 = word_count2 = complex_count2 = perc_complex_words2 = fog_index2 = uncer_score2 = constr_score2 = perc_uncer2 = perc_constr2 = perc_positive2 = perc_negative2 = 0\n",
        "  pos_score3 = neg_score3 = pol_score3 = avg_sent_len_val3 = word_count3 = complex_count3 = perc_complex_words3 = fog_index3 = uncer_score3 = constr_score3 = perc_uncer3 = perc_constr3 = perc_positive3 = perc_negative3 = 0\n",
        "  constr_whole_count = 0\n",
        "\n",
        "print(\"All operations on the dataframe have finished successfully\")"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All operations on the dataframe have finished successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZkH4PSsYZFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                                FUNCTION FOR FETCHING THE SECTION's DATA                                          |\n",
        "###################################################################################################################\n",
        "\n",
        "def fetch_sections_data(data):\n",
        "\n",
        "################################################################################\n",
        "#       Fetching the \"MANAGEMENT'S DISCUSSION AND ANALYSIS\" section             |\n",
        "################################################################################\n",
        "\n",
        "  topic1 = \"MANAGEMENT'S DISCUSSION AND ANALYSIS\"\n",
        "  topic1_start = [m.start() for m in re.finditer(topic1, data)]\n",
        "\n",
        "  if (len(topic1_start) == 0):\n",
        "    topic1 = \"MANAGEMENTS DISCUSSION AND ANALYSIS\"\n",
        "    topic1_start = [m.start() for m in re.finditer(topic1, data)]\n",
        "\n",
        "      \n",
        "  if (len(topic1_start) != 0):\n",
        "    #topic_1_data has the data from the point where topic1 begins\n",
        "    topic_1_data = data[topic1_start[0]:]\n",
        "    \n",
        "    item = \"ITEM\"\n",
        "    topic1_end = [m.start() for m in re.finditer(item, topic_1_data)]\n",
        "\n",
        "    if (len(topic1_end) == 0):\n",
        "      topic_1_data = topic_1_data[0:]\n",
        "    else:  \n",
        "      topic_1_data = topic_1_data[0:topic1_end[0]-1]\n",
        "    #topic_1_data ends at the point where topic1 ends\n",
        "  if (len(topic1_start) == 0):\n",
        "    topic_1_data = 0  \n",
        "\n",
        "#####################################################################################################\n",
        "#       Fetching the \"QUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK\" section            |\n",
        "#####################################################################################################\n",
        "\n",
        "  topic2 = \"QUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK\"\n",
        "  topic2_start = [m.start() for m in re.finditer(topic2, data)]\n",
        "  \n",
        "  if (len(topic2_start) != 0):\n",
        "\n",
        "    topic_2_data = data[topic2_start[0]:]\n",
        "\n",
        "    item = \"ITEM\"\n",
        "    topic2_end = [m.start() for m in re.finditer(item, topic_2_data)]\n",
        "    if (len(topic2_end) == 0):\n",
        "      topic_2_data = topic_2_data[0:]\n",
        "    else:  \n",
        "      topic_2_data = topic_2_data[0:topic2_end[0]-1]     \n",
        "  \n",
        "  if (len(topic2_start) == 0):\n",
        "    topic_2_data = 0 \n",
        "\n",
        "  #SECTION 3 - Risk Factors\n",
        "  topic3 = \"RISK FACTORS\"\n",
        "  topic3_start = [m.start() for m in re.finditer(topic3, data)]\n",
        "\n",
        "  if (len(topic3_start) != 0):\n",
        "\n",
        "    topic_3_data = data[topic3_start[0]:]\n",
        "    \n",
        "    item = \"ITEM\"\n",
        "    topic3_end = [m.start() for m in re.finditer(item, topic_3_data)]\n",
        "    \n",
        "    if (len(topic3_end) == 0):\n",
        "      topic_3_data = topic_3_data[0:]\n",
        "    else:  \n",
        "      topic_3_data = topic_3_data[0:topic3_end[0]-1]    \n",
        "\n",
        "  if (len(topic3_start) == 0):\n",
        "    topic_3_data = 0         \n",
        "\n",
        "  return topic_1_data, topic_2_data, topic_3_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdweKRPNWYx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                  DATA CLEANING - REMOVING THE WORDS PRESENT IN STOP WORDS LIST                                   |\n",
        "###################################################################################################################\n",
        "\n",
        "def data_cleaning(x1, x2, x3):\n",
        "\n",
        "  if (x1 != 0):\n",
        "    x1 = nltk.word_tokenize(x1)                                     \n",
        "    x1 = [word for word in x1 if word.lower() not in stop_words]  #Gets all the words which are not present in the stop words list\n",
        "    x1 = ' '.join(x1)                                             #Combines all the cleaned data into a string of words                                        \n",
        "\n",
        "  if (x2 != 0):\n",
        "    x2 = nltk.word_tokenize(x2)                                   #Tokenizes words in the list\n",
        "    x2 = [word for word in x2 if word.lower() not in stop_words]  #Gets all the words which are not present in the stop words list\n",
        "    x2 = ' '.join(x2)                                             #Combines all the cleaned data into a string of words                          \n",
        "\n",
        "\n",
        "  if (x3 != 0):\n",
        "    x3 = nltk.word_tokenize(x3)                                   #Tokenizes words in the list\n",
        "    x3 = [word for word in x3 if word.lower() not in stop_words]  #Gets all the words which are not present in the stop words list\n",
        "    x3 = ' '.join(x3)                                             #Combines all the cleaned data into a string of words\n",
        "\n",
        "  return x1, x2, x3                               \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMiBKnJtYs_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                 FUNCTION FOR CALCULATING POSITIVE SCORE, NEGATIVE SCORE AND POLARITY SCORE                       |\n",
        "###################################################################################################################\n",
        "\n",
        "def pos_neg_pol(x):\n",
        "\n",
        "  x      = x.translate(str.maketrans('','',string.punctuation)) #Removing the Punctuations from the string before tokenizing \n",
        "  tokens = nltk.word_tokenize(x)                                #Tokenizing the string into a list of words\n",
        "  tokens = [x.lower() for x in tokens]                          #Converting all the words in the list to lower case\n",
        "\n",
        "  pos_words = neg_words = 0\n",
        "\n",
        "  for word in tokens:\n",
        "    if word in positive_cleaned:\n",
        "      pos_words += 1\n",
        "    if word in negative_cleaned:\n",
        "      neg_words -= 1 \n",
        "\n",
        "  pos_len = pos_words\n",
        "  neg_len = neg_words * -1\n",
        "\n",
        "  pol_score = (pos_len - neg_len)/((pos_len + neg_len) + 0.000001)\n",
        "\n",
        "  return pos_len, neg_len, pol_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuTvCu2eZSoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                          FUNCTION FOR CALCULATING AVERAGE SENTENCE LENGTH IN SECTION'S DATA                      |\n",
        "###################################################################################################################\n",
        "\n",
        "def avg_sent_len(x):\n",
        "\n",
        "  no_sent = len(sent_tokenize(x))                               #Calculating the number of sentences in the whole data\n",
        "  x      = x.translate(str.maketrans('','',string.punctuation)) #Removing the Punctuations from the string before tokenizing\n",
        "  tokens = nltk.word_tokenize(x)                                #Tokenizing the string into a list of words\n",
        "  no_words = len(tokens)                                        #Calculating the number of words in the ddata\n",
        "\n",
        "  if (no_sent != 0):\n",
        "    avg_sent_len = round(no_words/no_sent)                      #Calculating the Average Sentence length\n",
        "  else:\n",
        "    avg_sent_len = 0\n",
        "\n",
        "  return avg_sent_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJOpb1gDZ9cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                    FUNCTION FOR CALCULATING WORD_COUNT, COMPLEX WORD COUNT AND PERC OF COMPLEX WORDS             |\n",
        "###################################################################################################################\n",
        "\n",
        "def complex_word_count(word, complex_count):\n",
        "\n",
        "    word   = word.translate(str.maketrans('','',string.punctuation)) #Removing the Punctuations from the string before tokenizing\n",
        "    tokens = nltk.word_tokenize(word)                                #Tokenizing using nltk.word_tokenize\n",
        "    no_words = len(tokens)                                           #Finding out the number of words\n",
        "    \n",
        "    complex_count = 0                                                #Initializing the complex_count variable to 0\n",
        "    for word in tokens:\n",
        "\n",
        "      word = word.lower()                                            #Converting all the words in the list to Lowercase\n",
        "\n",
        "      vowels = \"aeiou\"    \n",
        "\n",
        "      if (word.endswith((\"es\", \"ed\"))):                              #We are ignoring the words ending with es or ed in our calculation\n",
        "        count = 0\n",
        "\n",
        "      else:\n",
        "        count = 0\n",
        "        \n",
        "        for c in word:\n",
        "          if (c in vowels):\n",
        "            count = count + 1                                        #Counting the number of Vowels in each word\n",
        "\n",
        "        if (count > 2):                                              #If number of vowels > 2 then we are incrementing complex_count variable by 1\n",
        "          complex_count = complex_count + 1 \n",
        "\n",
        "    perc_complex_words = complex_count/no_words                      #Calculating the percentage of complex words\n",
        "\n",
        "    return no_words, complex_count, perc_complex_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSh2EqBoaSis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                        FUNCTION FOR CALCULATING UNCERTAINITY AND CONSTRAINING SCORE                              |\n",
        "###################################################################################################################\n",
        "\n",
        "def uncer_constr_calc(x):\n",
        "  \n",
        "  x      = x.translate(str.maketrans('','',string.punctuation)) #Removing the Punctuations from the string before tokenizing\n",
        "  tokens = nltk.word_tokenize(x)                                #Tokenizing the string into a list of words\n",
        "  tokens = [x.lower() for x in tokens]                          #Converting all the words in thee list to lowercase\n",
        "\n",
        "  uncer_words = constr_words = 0\n",
        "\n",
        "  for word in tokens:                                         \n",
        "    if word in uncertainity_words:                              #If word is present in uncertainity word list we increment uncer_words by 1\n",
        "      uncer_words  += 1\n",
        "    if word in constraining_words:                              #If word is present in constraining word list we increment constr_words by 1                \n",
        "      constr_words += 1 \n",
        "\n",
        "  uncer_count  = uncer_words\n",
        "  constr_count = constr_words\n",
        "\n",
        "  return uncer_count, constr_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc1L3wnixDIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                      FUNCTION FOR CALCULATING CONSTRAINING WORDS FOR THE WHOLE REPORT                            |\n",
        "###################################################################################################################\n",
        "\n",
        "def constr_whole_report(x):\n",
        "\n",
        "  x      = x.translate(str.maketrans('','',string.punctuation)) #Removing the Punctuations from the string before tokenizing\n",
        "  tokens = nltk.word_tokenize(x)                                #Tokenizing the string into a list of words\n",
        "  tokens = [x.lower() for x in tokens]                          #Converting all the words in thee list to lowercase\n",
        "\n",
        "  constr_whole_words = 0\n",
        "  for word in tokens:                                         \n",
        "\n",
        "    if word in constraining_words:                              #If word is present in constraining word list we increment constr_words by 1                \n",
        "      constr_whole_words += 1     \n",
        "      \n",
        "  return constr_whole_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyT_JqzsaztQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "ceea963e-f84e-48ab-bcce-fadf8462d8b4"
      },
      "source": [
        "############################################################################################################################################\n",
        "#                                                      FINAL OUTPUT                                                                         |                    |\n",
        "############################################################################################################################################\n",
        "\n",
        "#Removing the pre-fix http link at the beginning to keep values same as original file\n",
        "link = 'https://www.sec.gov/Archives/'\n",
        "secfname_or = secfname_or.reset_index(drop=True)\n",
        "file_rec['SECFNAME'] = secfname_or \n",
        "\n",
        "#Final output is stored in file_rec dataframe\n",
        "file_rec"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CIK</th>\n",
              "      <th>CONAME</th>\n",
              "      <th>FYRMO</th>\n",
              "      <th>FDATE</th>\n",
              "      <th>FORM</th>\n",
              "      <th>SECFNAME</th>\n",
              "      <th>mda_positive_score</th>\n",
              "      <th>mda_negative_score</th>\n",
              "      <th>mda_polarity_score</th>\n",
              "      <th>mda_average_sentence_length</th>\n",
              "      <th>mda_percentage_of_complex_words</th>\n",
              "      <th>mda_fog_index</th>\n",
              "      <th>mda_complex_word_count</th>\n",
              "      <th>mda_word_count</th>\n",
              "      <th>mda_uncertainty_score</th>\n",
              "      <th>mda_constraining_score</th>\n",
              "      <th>mda_positive_word_proportion</th>\n",
              "      <th>mda_negative_word_proportion</th>\n",
              "      <th>mda_uncertainty_word_proportion</th>\n",
              "      <th>mda_constraining_word_proportion</th>\n",
              "      <th>qqdmr_positive_score</th>\n",
              "      <th>qqdmr_negative_score</th>\n",
              "      <th>qqdmr_polarity_score</th>\n",
              "      <th>qqdmr_average_sentence_length</th>\n",
              "      <th>qqdmr_percentage_of_complex_words</th>\n",
              "      <th>qqdmr_fog_index</th>\n",
              "      <th>qqdmr_complex_word_count</th>\n",
              "      <th>qqdmr_word_count</th>\n",
              "      <th>qqdmr_uncertainty_score</th>\n",
              "      <th>qqdmr_constraining_score</th>\n",
              "      <th>qqdmr_positive_word_proportion</th>\n",
              "      <th>qqdmr_negative_word_proportion</th>\n",
              "      <th>qqdmr_uncertainty_word_proportion</th>\n",
              "      <th>qqdmr_constraining_word_proportion</th>\n",
              "      <th>rf_positive_score</th>\n",
              "      <th>rf_negative_score</th>\n",
              "      <th>rf_polarity_score</th>\n",
              "      <th>rf_average_sentence_length</th>\n",
              "      <th>rf_percentage_of_complex_words</th>\n",
              "      <th>rf_fog_index</th>\n",
              "      <th>rf_complex_word_count</th>\n",
              "      <th>rf_word_count</th>\n",
              "      <th>rf_uncertainty_score</th>\n",
              "      <th>rf_constraining_score</th>\n",
              "      <th>rf_positive_word_proportion</th>\n",
              "      <th>rf_negative_word_proportion</th>\n",
              "      <th>rf_uncertainty_word_proportion</th>\n",
              "      <th>rf_constraining_word_proportion</th>\n",
              "      <th>constraining_words_whole_report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199803</td>\n",
              "      <td>1998-03-06 00:00:00</td>\n",
              "      <td>10-K405</td>\n",
              "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
              "      <td>20</td>\n",
              "      <td>71</td>\n",
              "      <td>-0.56044</td>\n",
              "      <td>21</td>\n",
              "      <td>0.379893</td>\n",
              "      <td>8.55196</td>\n",
              "      <td>854</td>\n",
              "      <td>2248</td>\n",
              "      <td>30</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0088968</td>\n",
              "      <td>0.0315836</td>\n",
              "      <td>0.0133452</td>\n",
              "      <td>0.0044484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199805</td>\n",
              "      <td>1998-05-15 00:00:00</td>\n",
              "      <td>10-Q</td>\n",
              "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
              "      <td>11</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.661538</td>\n",
              "      <td>23</td>\n",
              "      <td>0.43683</td>\n",
              "      <td>9.37473</td>\n",
              "      <td>733</td>\n",
              "      <td>1678</td>\n",
              "      <td>54</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00655542</td>\n",
              "      <td>0.0321812</td>\n",
              "      <td>0.0321812</td>\n",
              "      <td>0.00178784</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199808</td>\n",
              "      <td>1998-08-13 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199811</td>\n",
              "      <td>1998-11-12 00:00:00</td>\n",
              "      <td>10-K/A</td>\n",
              "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
              "      <td>40</td>\n",
              "      <td>131</td>\n",
              "      <td>-0.532164</td>\n",
              "      <td>19</td>\n",
              "      <td>0.412589</td>\n",
              "      <td>7.76504</td>\n",
              "      <td>1678</td>\n",
              "      <td>4067</td>\n",
              "      <td>75</td>\n",
              "      <td>46</td>\n",
              "      <td>0.00983526</td>\n",
              "      <td>0.0322105</td>\n",
              "      <td>0.0184411</td>\n",
              "      <td>0.0113105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000003662</td>\n",
              "      <td>SUNBEAM CORP/FL/</td>\n",
              "      <td>199811</td>\n",
              "      <td>1998-11-16 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0000012239</td>\n",
              "      <td>SPHERIX INC</td>\n",
              "      <td>200704</td>\n",
              "      <td>2007-04-02 00:00:00</td>\n",
              "      <td>10-K</td>\n",
              "      <td>edgar/data/12239/0001104659-07-024804.txt</td>\n",
              "      <td>109</td>\n",
              "      <td>124</td>\n",
              "      <td>-0.0643777</td>\n",
              "      <td>13</td>\n",
              "      <td>0.388878</td>\n",
              "      <td>5.35555</td>\n",
              "      <td>3867</td>\n",
              "      <td>9944</td>\n",
              "      <td>89</td>\n",
              "      <td>84</td>\n",
              "      <td>0.0109614</td>\n",
              "      <td>0.0124698</td>\n",
              "      <td>0.00895012</td>\n",
              "      <td>0.0084473</td>\n",
              "      <td>85</td>\n",
              "      <td>87</td>\n",
              "      <td>-0.0116279</td>\n",
              "      <td>13</td>\n",
              "      <td>0.38697</td>\n",
              "      <td>5.35479</td>\n",
              "      <td>2946</td>\n",
              "      <td>7613</td>\n",
              "      <td>50</td>\n",
              "      <td>59</td>\n",
              "      <td>0.0111651</td>\n",
              "      <td>0.0114278</td>\n",
              "      <td>0.00656771</td>\n",
              "      <td>0.0077499</td>\n",
              "      <td>134</td>\n",
              "      <td>185</td>\n",
              "      <td>-0.159875</td>\n",
              "      <td>13</td>\n",
              "      <td>0.393503</td>\n",
              "      <td>5.3574</td>\n",
              "      <td>4676</td>\n",
              "      <td>11883</td>\n",
              "      <td>117</td>\n",
              "      <td>107</td>\n",
              "      <td>0.0112766</td>\n",
              "      <td>0.0155685</td>\n",
              "      <td>0.009846</td>\n",
              "      <td>0.00900446</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0000012239</td>\n",
              "      <td>SPHERIX INC</td>\n",
              "      <td>200705</td>\n",
              "      <td>2007-05-16 00:00:00</td>\n",
              "      <td>NT 10-Q</td>\n",
              "      <td>edgar/data/12239/0001104659-07-040463.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0000012239</td>\n",
              "      <td>SPHERIX INC</td>\n",
              "      <td>200705</td>\n",
              "      <td>2007-05-18 00:00:00</td>\n",
              "      <td>10-Q</td>\n",
              "      <td>edgar/data/12239/0001104659-07-041441.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0000012239</td>\n",
              "      <td>SPHERIX INC</td>\n",
              "      <td>200705</td>\n",
              "      <td>2007-05-23 00:00:00</td>\n",
              "      <td>10-K/A</td>\n",
              "      <td>edgar/data/12239/0001104659-07-042333.txt</td>\n",
              "      <td>109</td>\n",
              "      <td>124</td>\n",
              "      <td>-0.0643777</td>\n",
              "      <td>13</td>\n",
              "      <td>0.389317</td>\n",
              "      <td>5.35573</td>\n",
              "      <td>3841</td>\n",
              "      <td>9866</td>\n",
              "      <td>89</td>\n",
              "      <td>83</td>\n",
              "      <td>0.011048</td>\n",
              "      <td>0.0125684</td>\n",
              "      <td>0.00902088</td>\n",
              "      <td>0.00841273</td>\n",
              "      <td>85</td>\n",
              "      <td>87</td>\n",
              "      <td>-0.0116279</td>\n",
              "      <td>13</td>\n",
              "      <td>0.388056</td>\n",
              "      <td>5.35522</td>\n",
              "      <td>2924</td>\n",
              "      <td>7535</td>\n",
              "      <td>50</td>\n",
              "      <td>59</td>\n",
              "      <td>0.0112807</td>\n",
              "      <td>0.0115461</td>\n",
              "      <td>0.0066357</td>\n",
              "      <td>0.00783013</td>\n",
              "      <td>134</td>\n",
              "      <td>185</td>\n",
              "      <td>-0.159875</td>\n",
              "      <td>13</td>\n",
              "      <td>0.393868</td>\n",
              "      <td>5.35755</td>\n",
              "      <td>4650</td>\n",
              "      <td>11806</td>\n",
              "      <td>117</td>\n",
              "      <td>106</td>\n",
              "      <td>0.0113502</td>\n",
              "      <td>0.01567</td>\n",
              "      <td>0.00991022</td>\n",
              "      <td>0.00897849</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>0000012239</td>\n",
              "      <td>SPHERIX INC</td>\n",
              "      <td>200708</td>\n",
              "      <td>2007-08-14 00:00:00</td>\n",
              "      <td>10-Q</td>\n",
              "      <td>edgar/data/12239/0001104659-07-062470.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 49 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            CIK  ... constraining_words_whole_report\n",
              "0    0000003662  ...                            1452\n",
              "1    0000003662  ...                            1029\n",
              "2    0000003662  ...                               5\n",
              "3    0000003662  ...                             691\n",
              "4    0000003662  ...                               4\n",
              "..          ...  ...                             ...\n",
              "147  0000012239  ...                             130\n",
              "148  0000012239  ...                               0\n",
              "149  0000012239  ...                              21\n",
              "150  0000012239  ...                             129\n",
              "151  0000012239  ...                              34\n",
              "\n",
              "[152 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHZTpEPca6TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################################\n",
        "#                              EXPORTING THE OUTPUT TO CSV SHEET                                                 |\n",
        "###################################################################################################################\n",
        "\n",
        "with open('/content/drive/My Drive/Blackcoffer - Data Science Internship/Final_Submission_File.csv', 'w') as f:\n",
        "  file_rec.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}